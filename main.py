import re

# üî§ –°—É—Ñ—Ñ–∏–∫—Å—Ç–µ—Ä–¥–∏–Ω —Å”©–∑–¥“Ø–∫
derivational_suffixes = {
    "–¥”©–π": "Derivation=Simil", "–¥–∞–π": "Derivation=Simil", "–¥–µ–π": "Derivation=Simil", "–¥–æ–π": "Derivation=Simil",
    "–ª—É—É": "Derivation=AdjFromNoun", "—Ç—É—É": "Derivation=AdjFromNoun", "–¥“Ø“Ø": "Derivation=AdjFromNoun", "—Å—ã–∑": "Derivation=AdjFromNoun",
    "—á—ã–ª": "Derivation=NounFromAdj", "—á—ã": "Derivation=Agent", "—á–∏": "Derivation=Agent",
    "–ª—ã–∫": "Derivation=Abstr", "–¥—É–∫": "Derivation=Abstr", "–¥–∏–∫": "Derivation=Abstr", "—Ç“Ø–∫": "Derivation=Abstr",
    "—Ç–∞—à": "Derivation=VerbFromNoun",
    "–≥–∞–Ω": "VerbForm=Part", "–≥–µ–Ω": "VerbForm=Part", "–∫–∞–Ω": "VerbForm=Part", "–∫–µ–Ω": "VerbForm=Part",
    "—É—É—á—É": "Derivation=Agent", "“Ø“Ø—á“Ø": "Derivation=Agent",
    "–º–∞": "Derivation=NounFromVerb", "–º–µ": "Derivation=NounFromVerb", "–±–∞": "Derivation=NounFromVerb", "–±–µ": "Derivation=NounFromVerb"
}


def split_sentences(text):
    return re.split(r'(?<=[.!?])\s+', text.strip())


def guess_derivation(word, lemma):
    matched = [tag for suf, tag in derivational_suffixes.items() if word.endswith(suf)]
    return matched[0] if matched else "_"


def tokenize(sentence):
    # –¥–µ—Ñ–∏—Å –º–µ–Ω–µ–Ω —Ç–∞—Ç–∞–∞–ª —Å”©–∑–¥”©—Ä–¥“Ø –±”©–ª–±”©–π—Ç
    return re.findall(r'\w+(?:-\w+)*|[^\w\s]', sentence, re.UNICODE)


def annotate_sentence(sentence, sent_id, file_handle):
    words = tokenize(sentence)
    file_handle.write(f"# sent_id = {sent_id}\n")
    file_handle.write(f"# text = {sentence}\n")

    i = 0
    token_id = 1
    while i < len(words):
        # –≠–ö–ò —Å”©–∑–¥“Ø–∫ –∞–π–∫–∞—à—ã
        if i < len(words) - 1:
            w1, w2 = words[i], words[i+1]
            print(f"üëâ –ë—É–ª 2 —Å”©–∑ –±–∏—Ä –º–∞–∞–Ω–∏–¥–µ –∫–æ–ª–¥–æ–Ω—É–ª–≥–∞–Ω–±—ã: ‚Äú{w1} {w2}‚Äù? [Y/n]: ", end="")
            answer = input().lower()
            if answer in ["y", ""]:
                lemma1 = input(f"  –õ–µ–º–º–∞ '{w1}' (Enter = {w1.lower()}): ") or w1.lower()
                upos1 = input(f"  –¢–µ–≥–∏ '{w1}': ").upper()
                feats1 = guess_derivation(w1.lower(), lemma1)

                lemma2 = input(f"  –õ–µ–º–º–∞ '{w2}' (Enter = {w2.lower()}): ") or w2.lower()
                upos2 = input(f"  –¢–µ–≥–∏ '{w2}': ").upper()
                feats2 = guess_derivation(w2.lower(), lemma2)

                file_handle.write(f"{token_id}-{token_id+1}\t{w1} {w2}\t_\tMWE\t_\t_\t_\t_\t_\t_\n")
                file_handle.write(f"{token_id}\t{w1}\t{lemma1}\t{upos1}\t_\t{feats1}\t_\t_\t_\t_\n")
                file_handle.write(f"{token_id+1}\t{w2}\t{lemma2}\t{upos2}\t_\t{feats2}\t_\t_\t_\t_\n")
                i += 2
                token_id += 2
                continue

        # –ñ–∞–ª–≥—ã–∑ —Å”©–∑
        word = words[i]
        lemma = input(f"–°”©–∑: {word} | –õ–µ–º–º–∞ (Enter = {word.lower()}): ") or word.lower()
        upos = input(f"–¢–µ–≥–∏ (–º–∏—Å: NOUN, VERB, ADJ, ...): ").upper()
        feats = guess_derivation(word.lower(), lemma)
        file_handle.write(f"{token_id}\t{word}\t{lemma}\t{upos}\t_\t{feats}\t_\t_\t_\t_\n")
        token_id += 1
        i += 1

    file_handle.write("\n")


def main():
    input_file = "C:\\Users\\user\\PycharmProjects\\PythonProject3\\kyrgyz_text.txt"
    output_file = "kyrgyz_corpus.conllu"

    with open(input_file, "r", encoding="utf-8") as f:
        text = f.read()

    sentences = split_sentences(text)

    with open(output_file, "w", encoding="utf-8") as f_out:
        for i, sentence in enumerate(sentences, 1):
            print(f"\n=== –°“Ø–π–ª”©–º {i} ===")
            annotate_sentence(sentence, sent_id=i, file_handle=f_out)

    print(f"\n‚úÖ Corpus —Å–∞–∫—Ç–∞–ª–¥—ã: {output_file}")
    print(f"üìä –ñ–∞–ª–ø—ã —Å“Ø–π–ª”©–º–¥”©—Ä: {len(sentences)}")


if __name__ == "__main__":
    main()
